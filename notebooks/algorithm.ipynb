{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch as th\n",
    "import numpy as np\n",
    "from scripts.utils.utils import load_yaml, make_dir, save_json, load_json\n",
    "from scripts.pruning_models.model import calculate_reward_transition_matrices_new, calculate_q_matrix_avpruning, calculate_traces\n",
    "\n",
    "run = '1000000'\n",
    "n_nodes = 6\n",
    "n_steps = 8\n",
    "n_actions = 2\n",
    "\n",
    "\n",
    "selected_folder =  f'../data/{run}/selected'\n",
    "\n",
    "test_file = os.path.join(selected_folder, 'test.json')\n",
    "train_file = os.path.join(selected_folder, 'train.json')\n",
    "\n",
    "test_networks = load_json(test_file)\n",
    "train_networks = load_json(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = [-100, -20, 20, 140]\n",
    "n_rewards = len(rewards)\n",
    "reward_id_map = {r: i for i,r in enumerate(rewards)}\n",
    "rm = np.vectorize(lambda r: reward_id_map[int(r)])\n",
    "\n",
    "\n",
    "Q_mr_all = np.zeros((len(train_networks), n_steps, n_rewards)) # m, r\n",
    "O_mr_all = np.zeros((len(train_networks), n_steps, n_rewards)) # m, r\n",
    "\n",
    "for n, network in enumerate(train_networks):\n",
    "    # Indices:\n",
    "    #     n: network [0..n_network]\n",
    "    #     p: participant [0..n_participants]\n",
    "    #     s: source node of action [0..n_nodes]\n",
    "    #     t: target node of action [0..n_nodes]\n",
    "    #     a: action [0,1]\n",
    "    #     m: move / step within path [0..n_steps]\n",
    "    #     f: starting node of the network [0..n_nodes]\n",
    "    #     r: reward [0..n_rewards]\n",
    "\n",
    "    T, R, L = calculate_reward_transition_matrices_new(network, n_nodes)\n",
    "\n",
    "    RID = rm(R)\n",
    "    nb_classes = 6\n",
    "    RID = np.eye(n_rewards)[RID.reshape(-1)].reshape(n_nodes, n_actions, n_rewards)\n",
    "\n",
    "    Q = calculate_q_matrix_avpruning(R, T, n_steps, gamma_g=0.0, gamma_s=0.0)\n",
    "\n",
    "    OM = np.zeros((n_steps, n_nodes)) # m, s\n",
    "    starting_node = network['starting_node']\n",
    "    OM[0, starting_node] = 1\n",
    "    for m in range(1, n_steps):\n",
    "        OM[m] = np.einsum('s,sta->t',OM[m-1], T)\n",
    "\n",
    "    q_mr = np.einsum('ms,msa,sar->mr',OM, np.flip(Q, 0), RID) # m,r\n",
    "    o_mr = np.einsum('ms,sar->mr',OM, RID) # m,r\n",
    "\n",
    "    Q_mr_all[n] = q_mr\n",
    "    O_mr_all[n] = o_mr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22074/1625276511.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Q_mr_all[0] / O_mr_all[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[          nan,  480.        ,           nan,  520.        ],\n",
       "       [ 380.        ,  340.        ,  500.        ,           nan],\n",
       "       [ 320.        ,  320.        ,  480.        ,  400.        ],\n",
       "       [ 193.33333333,  233.33333333,  320.        ,  433.33333333],\n",
       "       [ 177.14285714,  184.        ,  320.        ,  269.09090909],\n",
       "       [  46.66666667,  111.2       ,  182.85714286,  278.46153846],\n",
       "       [  10.        ,   51.42857143,  160.        ,  138.46153846],\n",
       "       [-100.        ,  -20.        ,   20.        ,  140.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_mr_all[0] / O_mr_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_networks[0]['max_reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22074/1352934458.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  q_mr / o_mr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 600.        ,  560.        ,           nan,           nan],\n",
       "       [          nan,           nan,  520.        ,  640.        ],\n",
       "       [ 320.        ,  400.        ,  440.        ,  560.        ],\n",
       "       [ 180.        ,  420.        ,  300.        ,  420.        ],\n",
       "       [ 140.        ,  280.        ,  280.        ,  360.        ],\n",
       "       [  52.        ,  140.        ,  188.88888889,  274.54545455],\n",
       "       [  -9.23076923,  120.        ,  138.82352941,  160.        ],\n",
       "       [-100.        ,  -20.        ,   20.        ,  140.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_mr / o_mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_l_mr = Q_mr / O_mr\n",
    "Q_l_mr = np.nan_to_num(Q_l_mr, -1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 520.71428571,  500.        ,  410.        ,    0.        ],\n",
       "       [1000.        ,  404.48979592,  487.64705882,  608.75      ],\n",
       "       [ 287.30769231,  363.89380531,  405.30973451,  486.77966102],\n",
       "       [ 187.80487805,  278.51528384,  329.91596639,  437.4863388 ],\n",
       "       [ 142.00445434,  213.47826087,  264.8       ,  320.        ],\n",
       "       [  42.9004329 ,  114.13636364,  167.31092437,  281.49758454],\n",
       "       [ -14.87348735,   44.54244763,   99.17480999,  177.02479339],\n",
       "       [-100.        ,  -20.        ,   20.        ,  140.        ]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_fake = Q_l_mr.copy()\n",
    "Q_fake[1,0] = 1000\n",
    "Q_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "all_regret = []\n",
    "\n",
    "this_Q = Q_l_mr\n",
    "\n",
    "\n",
    "for network in test_networks:\n",
    "   #  R: s, a\n",
    "    T, R, L = calculate_reward_transition_matrices_new(network, n_nodes)\n",
    "    Q = calculate_q_matrix_avpruning(R, T, n_steps, gamma_g=0.0, gamma_s=0.0)\n",
    "\n",
    "    RID = rm(R)\n",
    "    nb_classes = 6\n",
    "    RID = np.eye(n_rewards)[RID.reshape(-1)].reshape(n_nodes, n_actions, n_rewards)\n",
    "\n",
    "    OM = np.zeros((n_steps+1, n_nodes)) # m, s\n",
    "    starting_node = network['starting_node']\n",
    "    OM[0, starting_node] = 1\n",
    "    P = np.zeros((n_steps, n_nodes, n_actions)) # m, s, a\n",
    "    exp_reward = 0\n",
    "    for m in range(0, n_steps):\n",
    "        q = np.einsum('sar,r->sa',RID, this_Q[m]) # s,a\n",
    "        P[m] = np.heaviside(q-q.mean(1, keepdims=True), 0.5) # s,a\n",
    "        OM[m+1] = np.einsum('s,sa,sta->t',OM[m], P[m], T)\n",
    "\n",
    "    reward = np.einsum('ms,msa,sa->',OM[:-1], P, R)\n",
    "    max_reward = Q[-1,starting_node].max()\n",
    "    regret = reward - max_reward\n",
    "    all_regret.append(regret)\n",
    "\n",
    "print(all_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 520.71428571,  500.        ,  410.        ,    0.        ],\n",
       "       [ 350.23255814,  404.48979592,  487.64705882,  608.75      ],\n",
       "       [ 287.30769231,  363.89380531,  405.30973451,  486.77966102],\n",
       "       [ 187.80487805,  278.51528384,  329.91596639,  437.4863388 ],\n",
       "       [ 142.00445434,  213.47826087,  264.8       ,  320.        ],\n",
       "       [  42.9004329 ,  114.13636364,  167.31092437,  281.49758454],\n",
       "       [ -14.87348735,   44.54244763,   99.17480999,  177.02479339],\n",
       "       [-100.        ,  -20.        ,   20.        ,  140.        ]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_l_mr"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8dd77bba1baced248a8a06b3d423a69f02665d6f465b986b031643d067a6fbff"
  },
  "kernelspec": {
   "display_name": "Python 3.9.3 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
