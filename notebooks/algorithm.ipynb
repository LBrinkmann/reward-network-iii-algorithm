{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch as th\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts.utils.utils import load_yaml, make_dir, save_json, load_json\n",
    "from scripts.pruning_models.model import calculate_reward_transition_matrices_new, calculate_q_matrix_avpruning, calculate_traces\n",
    "\n",
    "run = 'v2_100'\n",
    "n_nodes = 10\n",
    "n_steps = 8\n",
    "n_actions = 2\n",
    "\n",
    "\n",
    "selected_folder =  f'../data/{run}/selected'\n",
    "\n",
    "test_file = os.path.join(selected_folder, 'test.json')\n",
    "train_file = os.path.join(selected_folder, 'train.json')\n",
    "\n",
    "\n",
    "q_table_folder =  f'../data/{run}/q_table'\n",
    "make_dir(q_table_folder)\n",
    "\n",
    "q_table_file = os.path.join(q_table_folder, 'algorithm_1.json')\n",
    "\n",
    "test_networks = load_json(test_file)\n",
    "train_networks = load_json(train_file)\n",
    "train_networks = [n for n in train_networks if len(n['actions']) == 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = [-100, -20, 0, 20, 140]\n",
    "n_rewards = len(rewards)\n",
    "reward_id_map = {r: i for i,r in enumerate(rewards)}\n",
    "rm = np.vectorize(lambda r: reward_id_map[int(r)])\n",
    "\n",
    "\n",
    "Q_mr_all = np.zeros((len(train_networks), n_steps, n_rewards)) # m, r\n",
    "O_mr_all = np.zeros((len(train_networks), n_steps, n_rewards)) # m, r\n",
    "\n",
    "for n, network in enumerate(train_networks):\n",
    "    # Indices:\n",
    "    #     n: network [0..n_network]\n",
    "    #     p: participant [0..n_participants]\n",
    "    #     s: source node of action [0..n_nodes]\n",
    "    #     t: target node of action [0..n_nodes]\n",
    "    #     a: action [0,1]\n",
    "    #     m: move / step within path [0..n_steps]\n",
    "    #     f: starting node of the network [0..n_nodes]\n",
    "    #     r: reward [0..n_rewards]\n",
    "\n",
    "    T, R, L = calculate_reward_transition_matrices_new(network, n_nodes)\n",
    "\n",
    "    RID = rm(R)\n",
    "    RID = np.eye(n_rewards)[RID.reshape(-1)].reshape(n_nodes, n_actions, n_rewards)\n",
    "\n",
    "    Q = calculate_q_matrix_avpruning(R, T, n_steps, gamma_g=0.0, gamma_s=0.0)\n",
    "\n",
    "    OM = np.zeros((n_steps, n_nodes)) # m, s\n",
    "    starting_node = network['starting_node']\n",
    "    OM[0, starting_node] = 1\n",
    "    for m in range(1, n_steps):\n",
    "        OM[m] = np.einsum('s,sta->t',OM[m-1], T)\n",
    "\n",
    "    q_mr = np.einsum('ms,msa,sar->mr',OM, np.flip(Q, 0), RID) # m,r\n",
    "    o_mr = np.einsum('ms,sar->mr',OM, RID) # m,r\n",
    "\n",
    "    Q_mr_all[n] = q_mr\n",
    "    O_mr_all[n] = o_mr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/MPIB-BERLIN/brinkmann/repros/reward-network-ii/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "Q_l_mr = Q_mr_all.sum(0) / O_mr_all.sum(0)\n",
    "Q_l_mr = np.nan_to_num(Q_l_mr, -1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -587.08333333,    -2.27272727,    44.09090909,    36.2962963 ,\n",
       "            0.        ],\n",
       "       [ -634.92957746,   -88.65979381,  -354.47619048,  -213.27102804,\n",
       "            0.        ],\n",
       "       [ -693.7254902 ,  -173.29411765,  -472.56198347,  -333.98373984,\n",
       "            0.        ],\n",
       "       [ -612.        ,  -172.50773994,  -461.68618267,  -423.95918367,\n",
       "        -1000.        ],\n",
       "       [ -598.02030457,  -182.77070064,  -460.33039648,  -459.16919959,\n",
       "        -1000.        ],\n",
       "       [ -437.93103448,  -171.21096725,  -475.59380379,  -477.62623634,\n",
       "        -1000.        ],\n",
       "       [  -88.88888889,  -188.36943196,  -346.32752215,  -364.18118467,\n",
       "        -1000.        ],\n",
       "       [ -100.        ,   -20.        ,     0.        ,    20.        ,\n",
       "          140.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_l_mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Q_l_mr, columns=rewards)\n",
    "df.to_json(q_table_file, orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_fake = Q_l_mr.copy()\n",
    "# Q_fake[1,0] = 1000\n",
    "# Q_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-60.0, -179.375, -180.0, -340.0, -80.0, -160.0, -95.0, -260.0, -260.0, -160.0, -160.0, -95.78125, -140.0, -160.0, -228.125, -98.4375, -147.5, -141.25, -155.0, -160.0]\n"
     ]
    }
   ],
   "source": [
    "all_regret = []\n",
    "\n",
    "this_Q = Q_l_mr\n",
    "\n",
    "\n",
    "for network in test_networks:\n",
    "   #  R: s, a\n",
    "    T, R, L = calculate_reward_transition_matrices_new(network, n_nodes)\n",
    "    Q = calculate_q_matrix_avpruning(R, T, n_steps, gamma_g=0.0, gamma_s=0.0)\n",
    "\n",
    "    RID = rm(R)\n",
    "    nb_classes = 6\n",
    "    RID = np.eye(n_rewards)[RID.reshape(-1)].reshape(n_nodes, n_actions, n_rewards)\n",
    "\n",
    "    OM = np.zeros((n_steps+1, n_nodes)) # m, s\n",
    "    starting_node = network['starting_node']\n",
    "    OM[0, starting_node] = 1\n",
    "    P = np.zeros((n_steps, n_nodes, n_actions)) # m, s, a\n",
    "    exp_reward = 0\n",
    "    for m in range(0, n_steps):\n",
    "        q = np.einsum('sar,r->sa',RID, this_Q[m]) # s,a\n",
    "        P[m] = np.heaviside(q-q.mean(1, keepdims=True), 0.5) # s,a\n",
    "        OM[m+1] = np.einsum('s,sa,sta->t',OM[m], P[m], T)\n",
    "\n",
    "    reward = np.einsum('ms,msa,sa->',OM[:-1], P, R)\n",
    "    max_reward = Q[-1,starting_node].max()\n",
    "    regret = reward - max_reward\n",
    "    all_regret.append(regret)\n",
    "\n",
    "print(all_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -587.08333333,    -2.27272727,    44.09090909,    36.2962963 ,\n",
       "            0.        ],\n",
       "       [ -634.92957746,   -88.65979381,  -354.47619048,  -213.27102804,\n",
       "            0.        ],\n",
       "       [ -693.7254902 ,  -173.29411765,  -472.56198347,  -333.98373984,\n",
       "            0.        ],\n",
       "       [ -612.        ,  -172.50773994,  -461.68618267,  -423.95918367,\n",
       "        -1000.        ],\n",
       "       [ -598.02030457,  -182.77070064,  -460.33039648,  -459.16919959,\n",
       "        -1000.        ],\n",
       "       [ -437.93103448,  -171.21096725,  -475.59380379,  -477.62623634,\n",
       "        -1000.        ],\n",
       "       [  -88.88888889,  -188.36943196,  -346.32752215,  -364.18118467,\n",
       "        -1000.        ],\n",
       "       [ -100.        ,   -20.        ,     0.        ,    20.        ,\n",
       "          140.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_l_mr"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8dd77bba1baced248a8a06b3d423a69f02665d6f465b986b031643d067a6fbff"
  },
  "kernelspec": {
   "display_name": "Python 3.9.3 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
