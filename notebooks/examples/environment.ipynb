{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rn.utils.utils import save_json, make_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import groupby\n",
    "\n",
    "\n",
    "rewards = [-100, -20, 20, 140]\n",
    "n_rewards = len(rewards)\n",
    "reward_id_map = {r: i for i,r in enumerate(rewards)}\n",
    "\n",
    "def node_links(actions, **kwargs):\n",
    "    return {\n",
    "        source_node: sorted([\n",
    "            {'targetId': l['targetId'], 'reward': l['reward'], 'rewardId': reward_id_map[l['reward']]} \n",
    "            for l in links\n",
    "        ], key = lambda l: l['reward'])\n",
    "        for source_node, links in groupby(actions, lambda l: l['sourceId'])\n",
    "    }\n",
    "\n",
    "\n",
    "class NetworkEnvironments:\n",
    "    def __init__(self, networks, n_steps):\n",
    "        self.networks = [\n",
    "            {\n",
    "                'node_links': node_links(**n),\n",
    "                'starting_node': n['starting_node'],\n",
    "                'max_reward': n['max_reward']\n",
    "            }\n",
    "            for n in networks\n",
    "        ]\n",
    "        self.n_steps = n_steps\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        assert not self.done, 'Environment is done already.'\n",
    "        selected_link = self.node_links[self.node][action]\n",
    "        reward = selected_link['reward']\n",
    "        self.node = selected_link['targetId']\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.n_steps:\n",
    "            self.done = True\n",
    "            observation = None\n",
    "        else:\n",
    "            observation = self.observe(self.step_count, self.node_links[self.node])\n",
    "\n",
    "        return observation, reward, self.done, {'max_reward': self.max_reward}\n",
    "\n",
    "    @staticmethod\n",
    "    def observe(step_count, node_links):\n",
    "        return (step_count, *(nl['rewardId'] for nl in node_links))\n",
    "\n",
    "    def reset(self):\n",
    "        network = random.choice(self.networks)\n",
    "        self.node_links = network['node_links']\n",
    "        self.node = network['starting_node']\n",
    "        self.max_reward = network['max_reward']\n",
    "        self.step_count = 0\n",
    "        self.done = False\n",
    "        return self.observe(self.step_count, self.node_links[self.node])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c6aac55b9060d8c5e909fe78b15c7c8c111d482ebd90032ffdeb7e56d867e0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
